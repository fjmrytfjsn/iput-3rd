\documentclass{ltjsarticle}

\title{
    MNISTの学習における
    全結合層と畳み込み層の違いが
    学習時間と精度に与える影響の調査
}
\author{藤村勇仁}
\date{\today}

\input{macro}
\begin{document}
\input{titlepage}

\TableOfContents
\section{概要}
    本課題では、MNISTの学習において畳み込み層の有無が学習時間と精度にどのような影響を与えるかを調する。
    また、精度を維持したままモデルのサイズを小さくする方法を調査する。
    具体的には、全結合層のみのモデルと畳み込み層を含むモデルを比較し、
    学習時間と精度の関係を調べる。
    さらに、全結合層のみのモデルにおいて、精度を向上させるために全結合層のユニット数を増やすことでモデルのサイズと精度の関係を調べる。

\section{畳み込み層の有無による学習時間と精度の比較}
    MNISTデータセットを用いて、畳み込み層を含むモデルと全結合層のみのモデルを比較する。
    畳み込み層を含むモデルは、LMSにアップロードされているmnist.pyを途中結果の評価である、\verb|if batch_idx % 16 == 0:|内を削除して使用した。
    全結合層のみのモデルは、畳み込み層を含むモデルの計測に使用したコードのMyModelクラスを以下のように変更した。
    \begin{lstlisting}[language=python]
class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(1 * 28 * 28, 128)  # 全結合層
        self.fc2 = nn.Linear(128, 10)  # 全結合層

    def forward(self, xx):
        xx = self.flatten(xx)  # 1x28x28->784
        xx = self.fc1(xx)  # 784->128
        xx = nn.ReLU()(xx)
        xx = self.fc2(xx)
        return xx
    \end{lstlisting}

    \subsection{実行結果}
        畳み込み層を含むモデルの実行結果は以下のようになった。
        \begin{lstlisting}
==================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==================================================================================
MyModel                                  [1, 10]                   --
├─Conv2d: 1-1                            [1, 4, 26, 26]            40
├─Conv2d: 1-2                            [1, 4, 24, 24]            148
├─Flatten: 1-3                           [1, 2304]                 --
├─Linear: 1-4                            [1, 128]                  295,040
├─Linear: 1-5                            [1, 10]                   1,290
==================================================================================
Total params: 296,518
Trainable params: 296,518
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.41
==================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.04
Params size (MB): 1.19
Estimated Total Size (MB): 1.23
==================================================================================
Epoch: 1, Loss: 0.113473, Time: 6.84 sec
Accuracy on the test dataset: 96.03%
        \end{lstlisting}

        全結合層のみのモデルの実行結果は以下のようになった。
        \begin{lstlisting}
==================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==================================================================================
MyModel                                  [1, 10]                   --
├─Flatten: 1-1                           [1, 784]                  --
├─Linear: 1-2                            [1, 128]                  100,480
├─Linear: 1-3                            [1, 10]                   1,290
==================================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.10
==================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.41
Estimated Total Size (MB): 0.41
==================================================================================
Epoch: 1, Loss: 0.153714, Time: 5.87 sec
Accuracy on the test dataset: 95.38%
        \end{lstlisting}

    \subsection{考察}
        実行結果より、畳み込み層を含むモデルのパラメータ数は296,518であり、全結合層のみのモデルのパラメータ数は101,770であることがわかる。
        これにより、全結合層のみのモデルは畳み込み層を含むモデルに比べてパラメータ数が約3倍少ないことがわかる。
        さらに、学習時間は畳み込み層を含むモデルが約6.84秒、全結合層のみのモデルが約5.87秒であり、全結合層のみのモデルの方が約1.2倍早いことがわかる。
        また、精度は畳み込み層を含むモデルが96.03\%、全結合層のみのモデルが95.38\%であり、畳み込み層を含むモデルの方が約0.65\%高いことがわかる。
        以上の結果から、全結合層のみのモデルは畳み込み層を含むモデルに比べてパラメータ数が約3倍少なく、学習時間が約1.2倍早く、精度が約0.65\%低いことがわかる。
        ただし、この実行結果は誤差が大きく、学習時間や精度は実行環境や初期値に依存すると考えられるため、あくまで参考程度に留めておく必要がある。

\section{全結合層のユニット数を増やすことでモデルのサイズと精度の関係を調べる}
    全結合層のみのモデルにおいて、全結合層のパラメータ数を増やすことでモデルのサイズと精度の関係を調べる。
    % 具体的には、1つ目の全結合層の出力数を128から512、1024、2048、4096に変更し、それぞれのモデルの学習時間と精度を比較する。
    具体的には、1つ目の全結合層の出力数を64, 128, 192, 256, 320, 384, 448, 512, 576, 640, 704に変更し、それぞれのモデルの学習時間と精度を比較する。

    \subsection{実行結果}
        各出力数に対するモデルのパラメータ数とモデルのサイズと学習時間と精度は以下のようになった。
%         \begin{lstlisting}
% 出力数: 64, 学習時間: 6.05 sec, 精度: 94.02%
% 出力数: 128, 学習時間: 6.05 sec, 精度: 95.32%
% 出力数: 192, 学習時間: 6.05 sec, 精度: 95.86%
% 出力数: 256, 学習時間: 6.19 sec, 精度: 96.10%
% 出力数: 320, 学習時間: 6.33 sec, 精度: 95.91%
% 出力数: 384, 学習時間: 6.04 sec, 精度: 96.48%
% 出力数: 448, 学習時間: 5.93 sec, 精度: 96.53%
%         \end{lstlisting}
        \begin{lstlisting}
出力数: 64,  パラメータ数: 50,890,  サイズ: 0.21MB, 学習時間: 6.05 sec, 精度: 94.02%
出力数: 128, パラメータ数: 101,770, サイズ: 0.41MB, 学習時間: 6.05 sec, 精度: 95.32%
出力数: 192, パラメータ数: 152,650, サイズ: 0.62MB, 学習時間: 6.05 sec, 精度: 95.86%
出力数: 256, パラメータ数: 203,530, サイズ: 0.82MB, 学習時間: 6.19 sec, 精度: 96.10%
出力数: 320, パラメータ数: 254,410, サイズ: 1.02MB, 学習時間: 6.33 sec, 精度: 95.91%
出力数: 384, パラメータ数: 305,290, サイズ: 1.23MB, 学習時間: 6.04 sec, 精度: 96.48%
出力数: 448, パラメータ数: 356,170, サイズ: 1.43MB, 学習時間: 5.93 sec, 精度: 96.53%
出力数: 512, パラメータ数: 407,050, サイズ: 1.64MB, 学習時間: 6.19 sec, 精度: 96.62%
出力数: 576, パラメータ数: 457,930, サイズ: 1.84MB, 学習時間: 6.04 sec, 精度: 96.70%
出力数: 640, パラメータ数: 508,810, サイズ: 2.04MB, 学習時間: 6.21 sec, 精度: 96.89%
出力数: 704, パラメータ数: 559,690, サイズ: 2.25MB, 学習時間: 6.05 sec, 精度: 96.36%
        \end{lstlisting}

    \subsection{考察}
        実行結果より、サイズと精度の関係は\ref{fig:size-accu}のようになった。
        \fig[0.8]{size-accu}{サイズと精度の関係}{./materials/size-accu.png}
        この図より、サイズが大きくなるにつれて精度が向上することがわかる。
        ただし、サイズが大きくなるにつれて精度の向上は緩やかになっている。

        また、畳み込み層を含むモデルのパラメータ数296,518、サイズ1.23MB、精度96.03\%と、
        それにサイズが近い全結合層のみのモデルの出力数384のモデルのパラメータ数305,290、サイズ1.23MB、精度96.48\%を比較すると、
        全結合層のみのモデルの出力数を調節したほうが畳み込み層を含むモデルよりも精度が高いことがわかる。

        以上の結果から、今回のような単純なモデルにおいては、
        全結合層の出力数を増やす方が、畳み込み層を追加するよりも精度が高くなることがわかる。

        今回は全結合層の出力数を調節するにとどめたが、
        全結合層の数を増やしたり、畳み込み層の数を増やしたりすることで、
        より精度を向上させることができると考えられる。
\end{document}

